10/27
1. 打算重构一下整个项目的代码，即对SWeG和LDME算法的代码进行整理；

10/28
1. 整理了SWeG算法，目前没有什么问题；
2. 接下来整理LDME算法；

10/29
1. 整理完成LDME算法，目前也没有什么问题；
2. 可能要接着整理Greedy算法；
3. 在LDME算法分完组后，进行一个合并成功和失败的记数，目的是看LSH分组对顶点按相似程度划分的效果有多好。
   因为LDME算法虽然减小了最大的group_size,但是组内顶点是否真的很相似，使得组内合并次数尽可能多。
4. 尝试一个解决方法，利用一个层次的LSH分组，即先用较小的k进行分组，然后组内再用较大的k进行分组！

10/30
1. 实现Random算法，再加上一种随机合并的方式看看实验结果以及合并的顺序影响

10/31
1. 整理了Greedy算法，但还是存在一些问题：
   即当threshold=0时，继续合并顶点可能会导致压缩率下降，目前还不知道问题出现在哪里

11/1
1. 探索Graph Summarization中saving的意义，即合并一个顶点对能对压缩率提升多少？能否有公式推理证明？


11/25
1. 重新实现了一下分组函数和合并函数 dividePhase_new(), mergePhase_new(), 和 mergePhaseSequentialSplit()

11/28
1. sequential和hierarchical实现的方式都太简单了，没什么效果

12/13
1. 把数量超过1000的组内顶点都记录下来，然后再重新进行划分，看看具体有什么不同！